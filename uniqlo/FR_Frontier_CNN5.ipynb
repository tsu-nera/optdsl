{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 第1回 FR Frontier ：ファッション画像における洋服の「色」分類\n",
    "\n",
    "* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## preprocess\n",
    "Opencvをインストール\n",
    "\n",
    "    conda install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "HOME_DIR = current_dir\n",
    "#DATA_GIVEN_DIR = HOME_DIR+\"/data/given/\"\n",
    "DATA_GIVEN_DIR = \"/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "width = zz\n",
    "height = 667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for i in range(0,12399):\n",
    "    src = DATA_GIVEN_DIR + 'train/' + 'train_%i.jpg'%i\n",
    "    img = cv2.imread(src)zz\n",
    "\n",
    "    histR = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    histG = cv2.calcHist([img],[1],None,[256],[0,256])\n",
    "    histB = cv2.calcHist([img],[2],None,[256],[0,256])\n",
    "\n",
    "    histR = np.array(histR[1:])\n",
    "    histG = np.array(histG[1:])\n",
    "    histB = np.array(histB[1:])\n",
    "\n",
    "    hist = np.concatenate([histR, histG, histB], axis=1)\n",
    "    data_train.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-62eeb362c7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataXR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdataXG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataXB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "data_train = np.array(data_train)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "dataXR = mms.fit_transform(data_train[:,:,0])\n",
    "dataXG = mms.fit_transform(data_train[:,:,1])\n",
    "dataXB = mms.fit_transform(data_train[:,:,2])\n",
    "dataX = np.stack([dataXR, dataXG, dataXB], axis=2)\n",
    "dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "dataXR = stdsc.fit_transform(data_train[:,:,0])\n",
    "dataXG = stdsc.fit_transform(data_train[:,:,1])\n",
    "dataXB = stdsc.fit_transform(data_train[:,:,2])\n",
    "dataX = np.stack([dataXR, dataXG, dataXB], axis=2)\n",
    "dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_test = []\n",
    "for i in range(0, 9801):\n",
    "    src = DATA_GIVEN_DIR + 'test/' + 'test_%i.jpg'%i\n",
    "    img = cv2.imread(src)\n",
    "\n",
    "    histR = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    histG = cv2.calcHist([img],[1],None,[256],[0,256])\n",
    "    histB = cv2.calcHist([img],[2],None,[256],[0,256])\n",
    "    \n",
    "    histR = np.array(histR[1:])\n",
    "    histG = np.array(histG[1:])\n",
    "    histB = np.array(histB[1:])\n",
    "\n",
    "    hist = np.concatenate([histR, histG, histB], axis=1)\n",
    "    data_test.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_test = np.array(data_test)\n",
    "dataXR = mms.fit_transform(data_test[:,:,0])\n",
    "dataXG = mms.fit_transform(data_test[:,:,1])\n",
    "dataXB = mms.fit_transform(data_test[:,:,2])\n",
    "testX = np.stack([dataXR, dataXG, dataXB], axis=2)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataXR = stdsc.fit_transform(data_test[:,:,0])\n",
    "dataXG = stdsc.fit_transform(data_test[:,:,1])\n",
    "dataXB = stdsc.fit_transform(data_test[:,:,2])\n",
    "testX = np.stack([dataXR, dataXG, dataXB], axis=2)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train/valid 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_master = pd.read_table(DATA_GIVEN_DIR+'train_master.tsv', decimal='\\t')\n",
    "dataY = np.array(train_master['category_id'])\n",
    "dataY = np.array(pd.get_dummies(dataY).astype('float32'))\n",
    "dataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainX, validX = dataX[:10399], dataX[10399:]\n",
    "trainY, validY = dataY[:10399], dataY[10399:]\n",
    "trainX.shape, validX.shape, trainY.shape, validY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Conv1D, BatchNormalization, MaxPooling1D,GlobalAveragePooling1D, Activation\n",
    "from keras.optimizers import Nadam\n",
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nf=256\n",
    "p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return [\n",
    "    BatchNormalization(axis=1, input_shape=(255,3)),\n",
    "    Conv1D(nf,3, padding='same'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(nf,3, padding='same'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(nf,3, padding='same'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(nf,3, padding='same'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(24,3, padding='same'),\n",
    "    PReLU(),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dropout(p),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential(get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, epochs=50, batch_size=batch_size, validation_data=(validX, validY), \n",
    "          callbacks=[early_stop], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Inception1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.pooling import AveragePooling1D, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv1d_bn(x, nb_filter, nb_row, subsample_length=1):\n",
    "    x = Conv1D(nb_filter, nb_row, activation='relu', padding='same')(x)\n",
    "    return BatchNormalization(axis=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def incep_block(x):\n",
    "    branch1 = conv1d_bn(x, 32, 1, subsample_length=2)\n",
    "    branch5 = conv1d_bn(x, 24, 1)\n",
    "    branch5 = conv1d_bn(branch5, 32, 5, subsample_length=2)\n",
    "\n",
    "    branch3dbl = conv1d_bn(x, 32, 1)\n",
    "    branch3dbl = conv1d_bn(branch3dbl, 48, 3)\n",
    "    branch3dbl = conv1d_bn(branch3dbl, 48, 3, subsample_length=2)\n",
    "\n",
    "    branch_pool = AveragePooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(x, 16, 1)\n",
    "    return concatenate([branch1, branch5, branch3dbl, branch_pool], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp = Input((255,3)) \n",
    "x = BatchNormalization(axis=1)(inp)\n",
    "x = incep_block(x)\n",
    "x = incep_block(x)\n",
    "x = incep_block(x)\n",
    "x = Dropout(0.75)(x)\n",
    "x = Conv1D(24, 3, padding='same')(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "outp = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp], outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, epochs=30, batch_size=batch_size, validation_data=(validX, validY))b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model_with_param(num_layers, num_filters):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(axis=1, input_shape=(255,3)))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Conv1D(num_filters,3, padding='same'))\n",
    "        model.add(PReLU())\n",
    "        model.add(BatchNormalization(axis=1))\n",
    "        model.add(MaxPooling1D())\n",
    "    model.add(Conv1D(24,3, padding='same'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num_layers in [4,5]:\n",
    "    for num_filters in [512]:\n",
    "        log_string = 'logs/3/nl={},nf={}'.format(num_layers, num_filters)\n",
    "        tbcb = keras.callbacks.TensorBoard(log_dir=log_string)\n",
    "        model = get_model_with_param(num_layers, num_filters)\n",
    "        model.fit(trainX, trainY, epochs=30, batch_size=batch_size, validation_data=(validX, validY), callbacks=[tbcb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features = model.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels = np.argmax(test_features, axis=1)\n",
    "test_labels[:5]\n",
    "#test_features[:5]\n",
    "#array([20, 14, 17, 20, 23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for i in range(0, 9801):\n",
    "    filenames.append(\"test_%i.jpg\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Image\": filenames,\n",
    "                             \"Label\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'submission_conv2_256_4_std.csv'\n",
    "#np.savetxt(submission_file_name, subm, delimiter=',')\n",
    "submission.to_csv(submission_file_name, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pseude Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([trainX, testX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels_oh = np.array(pd.get_dummies(test_labels).astype('float32'))\n",
    "comb_label = np.concatenate([trainY, test_labels_oh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(comb_feat, comb_label, epochs=30, batch_size=batch_size, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opt]",
   "language": "python",
   "name": "conda-env-opt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "101px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
