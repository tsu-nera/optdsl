{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 第1回 FR Frontier ：ファッション画像における洋服の「色」分類\n",
    "\n",
    "* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## preprocess\n",
    "Opencvをインストール\n",
    "\n",
    "    conda install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "HOME_DIR = current_dir\n",
    "DATA_GIVEN_DIR = HOME_DIR+\"/data/given/\"\n",
    "#DATA_RESIZED_DIR = HOME_DIR+\"/data/resized/\"\n",
    "DATA_RESIZED_DIR = \"/input/\"\n",
    "DATA_MYDATA_DIR = HOME_DIR+\"/data/processed/\"\n",
    "DATA_TRANS_DIR = HOME_DIR+\"/data/transparent/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "width = 667\n",
    "height = 667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Transparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(DATA_TRANS_DIR)\n",
    "os.makedirs(DATA_TRANS_DIR+\"train/\")\n",
    "os.makedirs(DATA_TRANS_DIR+\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def trans_img(src, dst, width, height):\n",
    "    img = Image.open(src, 'r')\n",
    "\n",
    "    # 同じサイズの画像を作成\n",
    "    trans = Image.new('RGBA', img.size, (0, 0, 0, 0))\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pixel = img.getpixel( (x, y) )\n",
    "        \n",
    "            # 白なら処理しない\n",
    "            if pixel[0] == 255 and pixel[1] == 255 and pixel[2] == 255:\n",
    "                continue\n",
    "        \n",
    "            # 白以外なら、用意した画像にピクセルを書き込み\n",
    "            trans.putpixel( (x, y), pixel )\n",
    "    # リサイズ後の画像を保存\n",
    "    trans.save(dst, 'JPEG', optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-706fc198691e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_GIVEN_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_%i.jpg'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_TRANS_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"train/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_%i.jpg'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrans_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-c17fcce82b9c>\u001b[0m in \u001b[0;36mtrans_img\u001b[0;34m(src, dst, width, height)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mpixel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpixel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# 白なら処理しない\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# リサイズしないと時間かかりすぎ！！\n",
    "for i in range(0, 12399):\n",
    "    src = DATA_GIVEN_DIR + 'train/' + 'train_%i.jpg'%i\n",
    "    dst = DATA_TRANS_DIR + \"train/\" + 'train_%i.jpg'%i\n",
    "    trans_img(src, dst, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 9801):\n",
    "    src = DATA_GIVEN_DIR + 'test/' + 'test_%i.jpg'%i\n",
    "    dst = DATA_TRANS_DIR + \"test/\" + 'test_%i.jpg'%i\n",
    "    trans_img(src, dst, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, 12399):\n",
    "    src = DATA_RESIZED_DIR + 'train/' + 'train_%i.jpg'%i\n",
    "    img = cv2.imread(src)\n",
    "\n",
    "    histR = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    histG = cv2.calcHist([img],[1],None,[256],[0,256])\n",
    "    histB = cv2.calcHist([img],[2],None,[256],[0,256])\n",
    "\n",
    "    hist = np.concatenate([histR, histG, histB], axis=1)\n",
    "    data.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12399, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = np.array(data)\n",
    "dataX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train/valid/test  作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12399, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_master = pd.read_table('/input/train_master.tsv', decimal='\\t')\n",
    "dataY = np.array(train_master['category_id'])\n",
    "dataY = np.array(pd.get_dummies(dataY).astype('float32'))\n",
    "dataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 256, 3), (2399, 256, 3), (10000, 24), (2399, 24))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, validX = dataX[:10000], dataX[10000:]\n",
    "trainY, validY = dataY[:10000], dataY[10000:]\n",
    "trainX.shape, validX.shape, trainY.shape, validY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Conv2D, BatchNormalization, MaxPooling2D, ZeroPadding2D, Convolution2D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, Merge\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, SpatialDropout1D, Lambda\n",
    "\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,3))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb\n",
    "\n",
    "def VGG_16(size):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,)+size, output_shape=(3,)+size))\n",
    "    ConvBlock(model, 2, 64)\n",
    "    ConvBlock(model, 2, 128)\n",
    "    ConvBlock(model, 3, 256)\n",
    "    ConvBlock(model, 3, 512)\n",
    "    ConvBlock(model, 3, 512)\n",
    "\n",
    "    fname = 'vgg16_bn_conv.h5'\n",
    "    model.load_weights(get_file(fname, 'http://files.fast.ai/models/'+fname, cache_subdir='models'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 100 and 3 for 'lambda_13/sub' (op: 'Sub') with input shapes: [?,3,100,100], [1,1,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    672\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 100 and 3 for 'lambda_13/sub' (op: 'Sub') with input shapes: [?,3,100,100], [1,1,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b2db37f87888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"th\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-828a9ce12293>\u001b[0m in \u001b[0;36mVGG_16\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-828a9ce12293>\u001b[0m in \u001b[0;36mvgg_preprocess\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvgg_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvgg_mean\u001b[0m     \u001b[0;31m# subtract mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# reverse axis bgr->rgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m   \"\"\"\n\u001b[0;32m-> 2627\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2628\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tsu-nera/anaconda3/envs/opt/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 100 and 3 for 'lambda_13/sub' (op: 'Sub') with input shapes: [?,3,100,100], [1,1,3]."
     ]
    }
   ],
   "source": [
    "model = VGG_16((100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ccd81453c89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNadam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9a7881f870d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2399 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 4s - loss: 2.1824 - acc: 0.4365 - val_loss: 1.7536 - val_acc: 0.5782\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.6757 - acc: 0.5205 - val_loss: 1.3521 - val_acc: 0.6244\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.5073 - acc: 0.5508 - val_loss: 1.1071 - val_acc: 0.6524\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.4172 - acc: 0.5680 - val_loss: 1.0374 - val_acc: 0.6815\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.3600 - acc: 0.5813 - val_loss: 0.9728 - val_acc: 0.6957\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.3262 - acc: 0.5900 - val_loss: 0.9436 - val_acc: 0.6961\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.3042 - acc: 0.5979 - val_loss: 0.9185 - val_acc: 0.7074\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2890 - acc: 0.6007 - val_loss: 0.9490 - val_acc: 0.6932\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2749 - acc: 0.5990 - val_loss: 0.9442 - val_acc: 0.6886\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2779 - acc: 0.5994 - val_loss: 0.9525 - val_acc: 0.6945\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2714 - acc: 0.6021 - val_loss: 0.9209 - val_acc: 0.7011\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2553 - acc: 0.6070 - val_loss: 0.8927 - val_acc: 0.7186\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2432 - acc: 0.6128 - val_loss: 0.9123 - val_acc: 0.71860\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2364 - acc: 0.6131 - val_loss: 0.9122 - val_acc: 0.6995\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2439 - acc: 0.6073 - val_loss: 0.9026 - val_acc: 0.7186\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2236 - acc: 0.6154 - val_loss: 0.8981 - val_acc: 0.7132\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2052 - acc: 0.6233 - val_loss: 0.8794 - val_acc: 0.7207\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2175 - acc: 0.6145 - val_loss: 0.8899 - val_acc: 0.7249\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2018 - acc: 0.6186 - val_loss: 0.8761 - val_acc: 0.7165\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2093 - acc: 0.6101 - val_loss: 0.8672 - val_acc: 0.7207\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.2064 - acc: 0.6198 - val_loss: 0.8676 - val_acc: 0.7145\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1993 - acc: 0.6224 - val_loss: 0.8867 - val_acc: 0.7228\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1997 - acc: 0.6267 - val_loss: 0.8858 - val_acc: 0.7249\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1858 - acc: 0.6314 - val_loss: 0.9009 - val_acc: 0.7040\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1797 - acc: 0.6266 - val_loss: 0.8579 - val_acc: 0.7311\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1888 - acc: 0.6241 - val_loss: 0.8727 - val_acc: 0.7274\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1798 - acc: 0.6263 - val_loss: 0.8673 - val_acc: 0.7224\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1890 - acc: 0.6271 - val_loss: 0.8616 - val_acc: 0.7303\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1837 - acc: 0.6267 - val_loss: 0.8725 - val_acc: 0.7195\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1685 - acc: 0.6260 - val_loss: 0.8600 - val_acc: 0.7232\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1879 - acc: 0.6233 - val_loss: 0.8613 - val_acc: 0.7336\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1717 - acc: 0.6269 - val_loss: 0.8655 - val_acc: 0.7286\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1582 - acc: 0.6283 - val_loss: 0.8581 - val_acc: 0.7282\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1732 - acc: 0.6312 - val_loss: 0.8719 - val_acc: 0.7316\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1720 - acc: 0.6257 - val_loss: 0.8722 - val_acc: 0.73610.625\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1573 - acc: 0.6344 - val_loss: 0.8421 - val_acc: 0.7374\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1682 - acc: 0.6272 - val_loss: 0.8588 - val_acc: 0.7324\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1447 - acc: 0.6346 - val_loss: 0.8631 - val_acc: 0.7236\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1578 - acc: 0.6397 - val_loss: 0.8621 - val_acc: 0.7270\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1521 - acc: 0.6328 - val_loss: 0.8432 - val_acc: 0.7282\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1677 - acc: 0.6327 - val_loss: 0.8396 - val_acc: 0.7407\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1595 - acc: 0.6247 - val_loss: 0.8528 - val_acc: 0.7311\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1421 - acc: 0.6359 - val_loss: 0.8352 - val_acc: 0.7361\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1624 - acc: 0.6368 - val_loss: 0.8766 - val_acc: 0.7236\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1506 - acc: 0.6337 - val_loss: 0.8485 - val_acc: 0.7311\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1446 - acc: 0.6425 - val_loss: 0.8424 - val_acc: 0.7361\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1468 - acc: 0.6347 - val_loss: 0.8499 - val_acc: 0.7291\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1467 - acc: 0.6390 - val_loss: 0.8403 - val_acc: 0.7295\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1494 - acc: 0.6352 - val_loss: 0.8381 - val_acc: 0.7378\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 4s - loss: 1.1495 - acc: 0.6363 - val_loss: 0.8544 - val_acc: 0.7261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0a1185a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])\n",
    "conv2.fit(trainX, trainY, epochs=50, batch_size=batch_size, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv2.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2399 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 4s - loss: 2.4873 - acc: 0.3886 - val_loss: 1.2900 - val_acc: 0.5927\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 3s - loss: 1.7909 - acc: 0.5089 - val_loss: 1.1186 - val_acc: 0.6574\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 3s - loss: 1.5791 - acc: 0.5466 - val_loss: 1.0913 - val_acc: 0.6603\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 3s - loss: 1.4832 - acc: 0.5641 - val_loss: 1.0688 - val_acc: 0.6619\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 3s - loss: 1.4122 - acc: 0.5743 - val_loss: 1.0075 - val_acc: 0.6799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd03c15b320>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.fit(trainX, trainY, epochs=5, batch_size=batch_size, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2399 samples\n",
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 5s - loss: 1.3982 - acc: 0.5715 - val_loss: 0.9850 - val_acc: 0.6857\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.3502 - acc: 0.5826 - val_loss: 0.9256 - val_acc: 0.7045\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.3199 - acc: 0.5842 - val_loss: 0.9540 - val_acc: 0.6828\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.3131 - acc: 0.5950 - val_loss: 0.9464 - val_acc: 0.7103\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2978 - acc: 0.5970 - val_loss: 0.9284 - val_acc: 0.7099\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2978 - acc: 0.5921 - val_loss: 0.9365 - val_acc: 0.7020\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2807 - acc: 0.6022 - val_loss: 0.9191 - val_acc: 0.7115\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2660 - acc: 0.6031 - val_loss: 0.9315 - val_acc: 0.6945\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2676 - acc: 0.6021 - val_loss: 0.9230 - val_acc: 0.7070\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2590 - acc: 0.6117 - val_loss: 0.8995 - val_acc: 0.7140\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2275 - acc: 0.6188 - val_loss: 0.8998 - val_acc: 0.7145\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2496 - acc: 0.6071 - val_loss: 0.9088 - val_acc: 0.7090\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2471 - acc: 0.5989 - val_loss: 0.8990 - val_acc: 0.7216\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2445 - acc: 0.6104 - val_loss: 0.9379 - val_acc: 0.7036\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2148 - acc: 0.6171 - val_loss: 0.9372 - val_acc: 0.7003\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2312 - acc: 0.6149 - val_loss: 0.9289 - val_acc: 0.6965\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2196 - acc: 0.6104 - val_loss: 0.9195 - val_acc: 0.7174\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2421 - acc: 0.6107 - val_loss: 0.9203 - val_acc: 0.6990\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2192 - acc: 0.6138 - val_loss: 0.8707 - val_acc: 0.7291\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2186 - acc: 0.6156 - val_loss: 0.9041 - val_acc: 0.7257\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2101 - acc: 0.6177 - val_loss: 0.8790 - val_acc: 0.7245\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2144 - acc: 0.6149 - val_loss: 0.8902 - val_acc: 0.7145\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2133 - acc: 0.6204 - val_loss: 0.8880 - val_acc: 0.7161\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2074 - acc: 0.6165 - val_loss: 0.8666 - val_acc: 0.7232\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2252 - acc: 0.6139 - val_loss: 0.9299 - val_acc: 0.7182\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2052 - acc: 0.6174 - val_loss: 0.8935 - val_acc: 0.7216\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2062 - acc: 0.6169 - val_loss: 0.8847 - val_acc: 0.7161\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2092 - acc: 0.6161 - val_loss: 0.8511 - val_acc: 0.7266\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2025 - acc: 0.6210 - val_loss: 0.8581 - val_acc: 0.7299\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 3s - loss: 1.2075 - acc: 0.6158 - val_loss: 0.8529 - val_acc: 0.7241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd02f9c1fd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "conv2.fit(trainX, trainY, epochs=30, batch_size=batch_size, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2399 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 5s - loss: 1.1637 - acc: 0.6316 - val_loss: 0.9057 - val_acc: 0.7128\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1623 - acc: 0.6354 - val_loss: 0.9080 - val_acc: 0.7061\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1654 - acc: 0.6409 - val_loss: 0.8957 - val_acc: 0.7170\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1672 - acc: 0.6397 - val_loss: 0.8982 - val_acc: 0.7107\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1458 - acc: 0.6402 - val_loss: 0.9142 - val_acc: 0.7145\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1473 - acc: 0.6379 - val_loss: 0.8978 - val_acc: 0.7145\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1697 - acc: 0.6338 - val_loss: 0.8971 - val_acc: 0.7132\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1625 - acc: 0.6384 - val_loss: 0.9020 - val_acc: 0.7182\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1525 - acc: 0.6397 - val_loss: 0.8960 - val_acc: 0.7140\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1510 - acc: 0.6442 - val_loss: 0.8947 - val_acc: 0.7170\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1557 - acc: 0.6366 - val_loss: 0.9089 - val_acc: 0.7057\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1631 - acc: 0.6367 - val_loss: 0.8943 - val_acc: 0.7120\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1526 - acc: 0.6369 - val_loss: 0.8951 - val_acc: 0.7115\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1527 - acc: 0.6432 - val_loss: 0.9081 - val_acc: 0.7124\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1391 - acc: 0.6457 - val_loss: 0.8986 - val_acc: 0.7207\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1407 - acc: 0.6430 - val_loss: 0.8874 - val_acc: 0.7161\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1494 - acc: 0.6395 - val_loss: 0.8988 - val_acc: 0.7140\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1519 - acc: 0.6384 - val_loss: 0.8918 - val_acc: 0.7170\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1395 - acc: 0.6468 - val_loss: 0.8945 - val_acc: 0.7182\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 3s - loss: 1.1418 - acc: 0.6409 - val_loss: 0.8896 - val_acc: 0.7107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd031ee9828>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n",
    "conv2.fit(trainX, trainY, epochs=20, batch_size=batch_size, validation_data=(validX, validY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model.save_weights('2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, 9801):\n",
    "    src = DATA_RESIZED_DIR + 'test/' + 'test_%i.jpg'%i\n",
    "    img = cv2.imread(src)\n",
    "\n",
    "    histR = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    histG = cv2.calcHist([img],[1],None,[256],[0,256])\n",
    "    histB = cv2.calcHist([img],[2],None,[256],[0,256])\n",
    "\n",
    "    hist = np.concatenate([histR, histG, histB], axis=1)\n",
    "    data.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9801, 256, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = np.array(data)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features = conv2.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = np.argmax(test_features, axis=1)\n",
    "test_labels[:5]\n",
    "#test_features[:5]\n",
    "#array([20, 14, 17, 20, 23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for i in range(0, 9801):\n",
    "    filenames.append(\"test_%i.jpg\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Image\": filenames,\n",
    "                             \"Label\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'submission_cnn3.csv'\n",
    "#np.savetxt(submission_file_name, subm, delimiter=',')\n",
    "submission.to_csv(submission_file_name, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_cnn3.csv' target='_blank'>submission_cnn3.csv</a><br>"
      ],
      "text/plain": [
       "/output/submission_cnn3.csv"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opt]",
   "language": "python",
   "name": "conda-env-opt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "101px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
