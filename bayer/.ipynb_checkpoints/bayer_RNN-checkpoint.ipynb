{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 医薬情報テキストマイニングチャレンジ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/38/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('data/train.tsv')\n",
    "test = pd.read_table('data/test.tsv', header=None)\n",
    "num = len(data)\n",
    "test_num = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>便塊除去</td>\n",
       "      <td>摘便</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>アルツハイマ-認知症</td>\n",
       "      <td>アルツハイマー型認知症</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>熱傷（背部）</td>\n",
       "      <td>背部熱傷、程度不明（部位を限定しない）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.8.12骨盤-その他-前立腺癌</td>\n",
       "      <td>前立腺癌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>口のにがみ</td>\n",
       "      <td>苦味</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>軽度呼吸困難感</td>\n",
       "      <td>呼吸困難</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>両足関節偽痛風</td>\n",
       "      <td>偽痛風</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>内痔核出血</td>\n",
       "      <td>痔出血</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>背部皮脂欠乏性湿疹</td>\n",
       "      <td>皮脂欠乏性湿疹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>左側頭葉出血</td>\n",
       "      <td>脳出血</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 before                after\n",
       "0                  便塊除去                   摘便\n",
       "1            アルツハイマ-認知症          アルツハイマー型認知症\n",
       "2                熱傷（背部）  背部熱傷、程度不明（部位を限定しない）\n",
       "3  2015.8.12骨盤-その他-前立腺癌                 前立腺癌\n",
       "4                 口のにがみ                   苦味\n",
       "5               軽度呼吸困難感                 呼吸困難\n",
       "6               両足関節偽痛風                  偽痛風\n",
       "7                 内痔核出血                  痔出血\n",
       "8             背部皮脂欠乏性湿疹              皮脂欠乏性湿疹\n",
       "9                左側頭葉出血                  脳出血"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['after'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mecab をインストールする\n",
    "\n",
    "まずは、MeCabをインストール。\n",
    "\n",
    "       sudo apt-get install mecab mecab-naist-jdic mecab-ipadic-utf8 libmecab-dev\n",
    "       pip install mecab-python3\n",
    "\n",
    "Mecabには、医療辞書を使う(ComJisyo) \n",
    "[リリース ComeJisyo Linux用システム辞書 \\- ComeJisyo \\- OSDN](https://ja.osdn.net/projects/comedic/releases/44305)\n",
    "\n",
    "インストールでは、utf-8でインストールすることが必要。\n",
    "\n",
    "    ./configure --with-charset-=utf8　\n",
    "\n",
    "* [MeCabをUTF-8でインストールしたい。 - Qiita](http://qiita.com/junpooooow/items/0a7d13addc0acad10606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "#m = MeCab.Tagger(\"-Owakati\")\n",
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "#data['before'] = data['before'].apply(m.parseToNode)\n",
    "#test1 = test[0].apply(m.parseToNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS/EOS,*,*,*,*,*,*,*,*\n",
      "名詞,一般,*,*,*,*,足,アシ,アシ\n",
      "助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "動詞,自立,*,*,五段・カ行イ音便,基本形,ふらつく,フラツク,フラツク\n",
      "BOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "node = m.parseToNode(\"足がふらつく\")\n",
    "while node:\n",
    "    print(node.feature)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "befores = set()\n",
    "afters = set()\n",
    "for i, row in data.iterrows():\n",
    "    node = m.parseToNode(row[0])\n",
    "    while node:\n",
    "        if node.feature.startswith('名詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('形容詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('動詞'):\n",
    "            befores.add(node.surface)\n",
    "        node = node.next\n",
    "    afters.add(row[1])\n",
    "\n",
    "for i in test[0].iteritems():\n",
    "    node = m.parseToNode(i[1])\n",
    "    while node:\n",
    "        if node.feature.startswith('名詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('形容詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('動詞'):\n",
    "            befores.add(node.surface)\n",
    "        node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(befores)\n",
    "out_size = len(afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(words):\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "before_to_int, int_to_before = create_lookup_tables(befores)\n",
    "after_to_int, int_to_after = create_lookup_tables(afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 1, 8.30282208588957, 7.0, 20.92056222497029)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = data['before'].apply(len)\n",
    "(lens.max(), lens.min(), lens.mean(), lens.median(), lens.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.00000000e+00,   1.04000000e+02,   3.53000000e+02,\n",
       "          1.06500000e+03,   1.59700000e+03,   0.00000000e+00,\n",
       "          1.88700000e+03,   1.55900000e+03,   1.32000000e+03,\n",
       "          9.82000000e+02,   0.00000000e+00,   7.35000000e+02,\n",
       "          6.18000000e+02,   4.51000000e+02,   3.20000000e+02,\n",
       "          0.00000000e+00,   2.51000000e+02,   1.90000000e+02,\n",
       "          1.75000000e+02,   1.55000000e+02,   8.40000000e+01,\n",
       "          0.00000000e+00,   6.30000000e+01,   5.10000000e+01,\n",
       "          4.10000000e+01,   3.50000000e+01,   0.00000000e+00,\n",
       "          2.70000000e+01,   2.30000000e+01,   2.10000000e+01,\n",
       "          2.10000000e+01,   0.00000000e+00,   9.00000000e+00,\n",
       "          1.10000000e+01,   9.00000000e+00,   7.00000000e+00,\n",
       "          0.00000000e+00,   1.20000000e+01,   7.00000000e+00,\n",
       "          2.00000000e+00,   6.00000000e+00,   4.00000000e+00,\n",
       "          0.00000000e+00,   3.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([  1.  ,   1.81,   2.62,   3.43,   4.24,   5.05,   5.86,   6.67,\n",
       "          7.48,   8.29,   9.1 ,   9.91,  10.72,  11.53,  12.34,  13.15,\n",
       "         13.96,  14.77,  15.58,  16.39,  17.2 ,  18.01,  18.82,  19.63,\n",
       "         20.44,  21.25,  22.06,  22.87,  23.68,  24.49,  25.3 ,  26.11,\n",
       "         26.92,  27.73,  28.54,  29.35,  30.16,  30.97,  31.78,  32.59,\n",
       "         33.4 ,  34.21,  35.02,  35.83,  36.64,  37.45,  38.26,  39.07,\n",
       "         39.88,  40.69,  41.5 ,  42.31,  43.12,  43.93,  44.74,  45.55,\n",
       "         46.36,  47.17,  47.98,  48.79,  49.6 ,  50.41,  51.22,  52.03,\n",
       "         52.84,  53.65,  54.46,  55.27,  56.08,  56.89,  57.7 ,  58.51,\n",
       "         59.32,  60.13,  60.94,  61.75,  62.56,  63.37,  64.18,  64.99,\n",
       "         65.8 ,  66.61,  67.42,  68.23,  69.04,  69.85,  70.66,  71.47,\n",
       "         72.28,  73.09,  73.9 ,  74.71,  75.52,  76.33,  77.14,  77.95,\n",
       "         78.76,  79.57,  80.38,  81.19,  82.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97ea818860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seq_len = 20\n",
    "m2 = MeCab.Tagger(\"-Owakati\")\n",
    "data['before'] = data['before'].apply(m2.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY= [], []\n",
    "for i, row in data.iterrows():\n",
    "    xl = []\n",
    "    for w in row['before'].split():\n",
    "#        if len(xl) < seq_len:\n",
    "        try:\n",
    "            xl.append(before_to_int[w])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    trainX.append(xl)\n",
    "    trainY.append(after_to_int[row['after']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2605, 3048, 8479],\n",
       "  [4063, 4416, 6132],\n",
       "  [5413, 2289],\n",
       "  [5118, 1456, 7798, 1456, 5367, 454, 4416, 619, 4416, 5439],\n",
       "  [9034, 227, 6843],\n",
       "  [613, 1804, 5252],\n",
       "  [3251, 2978, 8427],\n",
       "  [2790, 5407],\n",
       "  [2289, 3303, 7570, 1933, 2395],\n",
       "  [6887, 8211, 5407]],\n",
       " [3697, 2499, 679, 1368, 3790, 3165, 2479, 4197, 3131, 212])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(trainX), len(trainY)\n",
    "trainX[:10], trainY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = test[0].apply(m2.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = []\n",
    "\n",
    "for i, row in test1.iteritems():\n",
    "    xl = []\n",
    "    for w in row.split():\n",
    "        try:\n",
    "            xl.append(before_to_int[w])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    testX.append(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seq_len = 20\n",
    "from keras.preprocessing import sequence\n",
    "trainX = sequence.pad_sequences(trainX, maxlen=seq_len, value=0, padding='post')\n",
    "testX = sequence.pad_sequences(testX, maxlen=seq_len, value=0, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2605, 3048, 8479,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4063, 4416, 6132,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [5413, 2289,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [5118, 1456, 7798, 1456, 5367,  454, 4416,  619, 4416, 5439,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [9034,  227, 6843,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 613, 1804, 5252,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [3251, 2978, 8427,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [2790, 5407,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [2289, 3303, 7570, 1933, 2395,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6887, 8211, 5407,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32),\n",
       " [3697, 2499, 679, 1368, 3790, 3165, 2479, 4197, 3131, 212],\n",
       " array([[2448, 7021, 2698,  227, 6909, 7829, 5627, 1933, 5407,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [2575, 3251, 3120,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4249, 7146,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6887, 4566,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [5540,  557, 3605,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4966, 8264, 3886,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4785, 5330,  227, 2088, 5252,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [7571,  227, 1708,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4181,  759, 5417,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6054, 7399,  338,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:10], trainY[:10], testX[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 20), (10000, 4217), (2225, 20), (2225, 4217), (12226, 20))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "testX = np.array(testX)\n",
    "validX = trainX[:2225]\n",
    "trainX = trainX[2225:]\n",
    "trainY = to_categorical(trainY)\n",
    "validY = trainY[:2225]\n",
    "trainY = trainY[2225:]\n",
    "trainX.shape, trainY.shape, validX.shape, validY.shape, testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    return [\n",
    "    Embedding(vocab_size, features, input_length=seq_len),\n",
    "    BatchNormalization(),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(out_size, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential(get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2225 samples\n",
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 22s - loss: 8.0949 - acc: 0.0389 - val_loss: 8.0797 - val_acc: 0.0427\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 22s - loss: 7.7409 - acc: 0.0402 - val_loss: 8.2615 - val_acc: 0.0153\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 21s - loss: 7.5535 - acc: 0.0398 - val_loss: 8.2714 - val_acc: 0.0409\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 22s - loss: 7.3117 - acc: 0.0402 - val_loss: 8.2658 - val_acc: 0.0387\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 23s - loss: 7.0983 - acc: 0.0408 - val_loss: 8.1587 - val_acc: 0.0351\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 26s - loss: 6.8938 - acc: 0.0403 - val_loss: 8.1462 - val_acc: 0.0319\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 24s - loss: 6.7230 - acc: 0.0396 - val_loss: 8.2214 - val_acc: 0.0274\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 20s - loss: 6.5787 - acc: 0.0398 - val_loss: 8.1332 - val_acc: 0.0328\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 21s - loss: 6.4429 - acc: 0.0407 - val_loss: 8.2888 - val_acc: 0.0333\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 23s - loss: 6.3335 - acc: 0.0445 - val_loss: 8.2600 - val_acc: 0.0351\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 23s - loss: 6.2171 - acc: 0.0434 - val_loss: 8.2391 - val_acc: 0.0252\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 23s - loss: 6.0895 - acc: 0.0487 - val_loss: 8.3066 - val_acc: 0.0301\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 23s - loss: 5.9855 - acc: 0.0491 - val_loss: 8.2852 - val_acc: 0.0297\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 25s - loss: 5.8583 - acc: 0.0559 - val_loss: 8.2301 - val_acc: 0.0463\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 22s - loss: 5.7483 - acc: 0.0624 - val_loss: 8.2357 - val_acc: 0.0454\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 20s - loss: 5.6250 - acc: 0.0635 - val_loss: 8.2614 - val_acc: 0.0512\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 20s - loss: 5.5186 - acc: 0.0707 - val_loss: 8.3500 - val_acc: 0.0481\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 22s - loss: 5.4171 - acc: 0.0751 - val_loss: 8.2402 - val_acc: 0.0544\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 22s - loss: 5.3034 - acc: 0.0806 - val_loss: 8.2062 - val_acc: 0.0530\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 20s - loss: 5.1756 - acc: 0.0862 - val_loss: 8.1572 - val_acc: 0.0620\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 22s - loss: 5.0862 - acc: 0.0969 - val_loss: 8.2270 - val_acc: 0.0737\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.9729 - acc: 0.1003 - val_loss: 8.1633 - val_acc: 0.0912\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.8532 - acc: 0.1135 - val_loss: 8.1359 - val_acc: 0.0867\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 20s - loss: 4.7598 - acc: 0.1170 - val_loss: 8.1327 - val_acc: 0.0953\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.6465 - acc: 0.1247 - val_loss: 8.1067 - val_acc: 0.1034\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.5565 - acc: 0.1333 - val_loss: 8.1414 - val_acc: 0.1043\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.4686 - acc: 0.1446 - val_loss: 8.0966 - val_acc: 0.1164\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 22s - loss: 4.3713 - acc: 0.1522 - val_loss: 8.1372 - val_acc: 0.1106\n",
      "Epoch 29/30\n",
      " 5504/10000 [===============>..............] - ETA: 9s - loss: 4.2198 - acc: 0.1621"
     ]
    }
   ],
   "source": [
    "rnn.fit(trainX, trainY, validation_data=(validX, validY), epochs=30, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = conv2.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 = np.argmax(preds[0])\n",
    "int_to_after[i1], i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame(columns=[\"before\", \"after\"])\n",
    "for i in range(0, test_num):\n",
    "    for id in np.argsort(preds[i])[::-1][:3]:\n",
    "        series = pd.DataFrame([[test[0][i], int_to_after[id]]], columns=out.columns)\n",
    "        out = out.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = \"submission_conv2_20.tsv\"\n",
    "out.to_csv(subm_name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileLink(subm_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
