{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 医薬情報テキストマイニングチャレンジ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/38/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('data/train.tsv')\n",
    "test = pd.read_table('data/test.tsv', header=None)\n",
    "num = len(data)\n",
    "test_num = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>便塊除去</td>\n",
       "      <td>摘便</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>アルツハイマ-認知症</td>\n",
       "      <td>アルツハイマー型認知症</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>熱傷（背部）</td>\n",
       "      <td>背部熱傷、程度不明（部位を限定しない）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.8.12骨盤-その他-前立腺癌</td>\n",
       "      <td>前立腺癌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>口のにがみ</td>\n",
       "      <td>苦味</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>軽度呼吸困難感</td>\n",
       "      <td>呼吸困難</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>両足関節偽痛風</td>\n",
       "      <td>偽痛風</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>内痔核出血</td>\n",
       "      <td>痔出血</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>背部皮脂欠乏性湿疹</td>\n",
       "      <td>皮脂欠乏性湿疹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>左側頭葉出血</td>\n",
       "      <td>脳出血</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 before                after\n",
       "0                  便塊除去                   摘便\n",
       "1            アルツハイマ-認知症          アルツハイマー型認知症\n",
       "2                熱傷（背部）  背部熱傷、程度不明（部位を限定しない）\n",
       "3  2015.8.12骨盤-その他-前立腺癌                 前立腺癌\n",
       "4                 口のにがみ                   苦味\n",
       "5               軽度呼吸困難感                 呼吸困難\n",
       "6               両足関節偽痛風                  偽痛風\n",
       "7                 内痔核出血                  痔出血\n",
       "8             背部皮脂欠乏性湿疹              皮脂欠乏性湿疹\n",
       "9                左側頭葉出血                  脳出血"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['after'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mecab をインストールする\n",
    "\n",
    "まずは、MeCabをインストール。\n",
    "\n",
    "       sudo apt-get install mecab mecab-naist-jdic mecab-ipadic-utf8 libmecab-dev\n",
    "       pip install mecab-python3\n",
    "\n",
    "Mecabには、医療辞書を使う(ComJisyo) \n",
    "[リリース ComeJisyo Linux用システム辞書 \\- ComeJisyo \\- OSDN](https://ja.osdn.net/projects/comedic/releases/44305)\n",
    "\n",
    "インストールでは、utf-8でインストールすることが必要。\n",
    "\n",
    "    ./configure --with-charset-=utf8　\n",
    "\n",
    "* [MeCabをUTF-8でインストールしたい。 - Qiita](http://qiita.com/junpooooow/items/0a7d13addc0acad10606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "#m = MeCab.Tagger(\"-Owakati\")\n",
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "#data['before'] = data['before'].apply(m.parseToNode)\n",
    "#test1 = test[0].apply(m.parseToNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS/EOS,*,*,*,*,*,*,*,*\n",
      "名詞,一般,*,*,*,*,足,アシ,アシ\n",
      "助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "動詞,自立,*,*,五段・カ行イ音便,基本形,ふらつく,フラツク,フラツク\n",
      "BOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "node = m.parseToNode(\"足がふらつく\")\n",
    "while node:\n",
    "    print(node.feature)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "befores = set()\n",
    "afters = set()\n",
    "for i, row in data.iterrows():\n",
    "    node = m.parseToNode(row[0])\n",
    "    while node:\n",
    "        if node.feature.startswith('名詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('形容詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('動詞'):\n",
    "            befores.add(node.surface)\n",
    "        node = node.next\n",
    "    afters.add(row[1])\n",
    "\n",
    "for i in test[0].iteritems():\n",
    "    node = m.parseToNode(i[1])\n",
    "    while node:\n",
    "        if node.feature.startswith('名詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('形容詞'):\n",
    "            befores.add(node.surface)\n",
    "        if node.feature.startswith('動詞'):\n",
    "            befores.add(node.surface)\n",
    "        node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9331\n",
      "9331\n"
     ]
    }
   ],
   "source": [
    "print(len(befores))\n",
    "#befores.discard('(')\n",
    "#befores.discard(')')\n",
    "#befores.discard('（')\n",
    "#befores.discard('）')\n",
    "#befores.discard('[')\n",
    "#befores.discard(']')\n",
    "#befores.discard('」')\n",
    "#befores.discard('「')\n",
    "#befores.discard('【')\n",
    "#befores.discard('】')\n",
    "#befores.discard('『')\n",
    "#befores.discard('』')\n",
    "\n",
    "#befores.discard(\"0\")\n",
    "#befores.discard(\"1\")\n",
    "#befores.discard('2')\n",
    "#befores.discard('3')\n",
    "#befores.discard('4')\n",
    "#befores.discard('5')\n",
    "#befores.discard('6')\n",
    "#befores.discard('7')\n",
    "#befores.discard('8')\n",
    "#befores.discard('9')\n",
    "#befores.discard('2015')\n",
    "#befores.discard('12')\n",
    "\n",
    "#befores.discard('↓')\n",
    "#befores.discard('↑')\n",
    "#befores.discard('→')\n",
    "#befores.discard('←')\n",
    "#befores.discard('〜')\n",
    "#befores.discard('~')\n",
    "#befores.discard('.')\n",
    "#befores.discard(',')\n",
    "#befores.discard('（＇')\n",
    "#befores.discard('＞')\n",
    "#befores.discard('＜')\n",
    "#befores.discard('>')\n",
    "#befores.discard('<')\n",
    "#befores.discard('）(')\n",
    "#befores.discard('（+)')\n",
    "#befores.discard('（±）')\n",
    "#befores.discard('-')\n",
    "print(len(befores))\n",
    "vocab_size = len(befores)\n",
    "out_size = len(afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(words):\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "before_to_int, int_to_before = create_lookup_tables(befores)\n",
    "after_to_int, int_to_after = create_lookup_tables(afters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 1, 8.30282208588957, 7.0, 20.92056222497029)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = data['before'].apply(len)\n",
    "(lens.max(), lens.min(), lens.mean(), lens.median(), lens.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.00000000e+00,   1.04000000e+02,   3.53000000e+02,\n",
       "          1.06500000e+03,   1.59700000e+03,   0.00000000e+00,\n",
       "          1.88700000e+03,   1.55900000e+03,   1.32000000e+03,\n",
       "          9.82000000e+02,   0.00000000e+00,   7.35000000e+02,\n",
       "          6.18000000e+02,   4.51000000e+02,   3.20000000e+02,\n",
       "          0.00000000e+00,   2.51000000e+02,   1.90000000e+02,\n",
       "          1.75000000e+02,   1.55000000e+02,   8.40000000e+01,\n",
       "          0.00000000e+00,   6.30000000e+01,   5.10000000e+01,\n",
       "          4.10000000e+01,   3.50000000e+01,   0.00000000e+00,\n",
       "          2.70000000e+01,   2.30000000e+01,   2.10000000e+01,\n",
       "          2.10000000e+01,   0.00000000e+00,   9.00000000e+00,\n",
       "          1.10000000e+01,   9.00000000e+00,   7.00000000e+00,\n",
       "          0.00000000e+00,   1.20000000e+01,   7.00000000e+00,\n",
       "          2.00000000e+00,   6.00000000e+00,   4.00000000e+00,\n",
       "          0.00000000e+00,   3.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "          3.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([  1.  ,   1.81,   2.62,   3.43,   4.24,   5.05,   5.86,   6.67,\n",
       "          7.48,   8.29,   9.1 ,   9.91,  10.72,  11.53,  12.34,  13.15,\n",
       "         13.96,  14.77,  15.58,  16.39,  17.2 ,  18.01,  18.82,  19.63,\n",
       "         20.44,  21.25,  22.06,  22.87,  23.68,  24.49,  25.3 ,  26.11,\n",
       "         26.92,  27.73,  28.54,  29.35,  30.16,  30.97,  31.78,  32.59,\n",
       "         33.4 ,  34.21,  35.02,  35.83,  36.64,  37.45,  38.26,  39.07,\n",
       "         39.88,  40.69,  41.5 ,  42.31,  43.12,  43.93,  44.74,  45.55,\n",
       "         46.36,  47.17,  47.98,  48.79,  49.6 ,  50.41,  51.22,  52.03,\n",
       "         52.84,  53.65,  54.46,  55.27,  56.08,  56.89,  57.7 ,  58.51,\n",
       "         59.32,  60.13,  60.94,  61.75,  62.56,  63.37,  64.18,  64.99,\n",
       "         65.8 ,  66.61,  67.42,  68.23,  69.04,  69.85,  70.66,  71.47,\n",
       "         72.28,  73.09,  73.9 ,  74.71,  75.52,  76.33,  77.14,  77.95,\n",
       "         78.76,  79.57,  80.38,  81.19,  82.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNcwQkKSG/X9SbSq9EFrvLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c6e7c1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lens, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seq_len = 20\n",
    "m2 = MeCab.Tagger(\"-Owakati\")\n",
    "data['before'] = data['before'].apply(m2.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY= [], []\n",
    "for i, row in data.iterrows():\n",
    "    xl = []\n",
    "    for w in row['before'].split():\n",
    "#        if len(xl) < seq_len:\n",
    "        try:\n",
    "            xl.append(before_to_int[w])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    trainX.append(xl)\n",
    "    trainY.append(after_to_int[row['after']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[2481, 3719, 6974],\n",
       "  [3596, 5099, 7836],\n",
       "  [6968, 491],\n",
       "  [2115, 7610, 985, 7610, 8754, 2987, 5099, 5437, 5099, 7738],\n",
       "  [9030, 2026, 578],\n",
       "  [8697, 9082, 4933],\n",
       "  [5980, 2568, 1900],\n",
       "  [6003, 2510],\n",
       "  [491, 9052, 6172, 8932, 8128],\n",
       "  [957, 5196, 2510]],\n",
       " [3050, 3138, 117, 1296, 867, 3715, 3426, 1222, 2473, 922])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(trainX), len(trainY)\n",
    "trainX[:10], trainY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1 = test[0].apply(m2.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = []\n",
    "\n",
    "for i, row in test1.iteritems():\n",
    "    xl = []\n",
    "    for w in row.split():\n",
    "        try:\n",
    "            xl.append(before_to_int[w])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    testX.append(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seq_len = 20\n",
    "from keras.preprocessing import sequence\n",
    "trainX = sequence.pad_sequences(trainX, maxlen=seq_len, value=0, padding='post')\n",
    "testX = sequence.pad_sequences(testX, maxlen=seq_len, value=0, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2481, 3719, 6974,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [3596, 5099, 7836,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6968,  491,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [2115, 7610,  985, 7610, 8754, 2987, 5099, 5437, 5099, 7738,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [9030, 2026,  578,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8697, 9082, 4933,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [5980, 2568, 1900,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6003, 2510,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 491, 9052, 6172, 8932, 8128,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 957, 5196, 2510,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32),\n",
       " [3050, 3138, 117, 1296, 867, 3715, 3426, 1222, 2473, 922],\n",
       " array([[8470, 4760, 5770, 2026, 4117, 7613, 8696, 8932, 2510,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4751, 5980, 4894,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [6933, 8779,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 957, 8690,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [4807, 8700, 2557,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [1627, 2158,  663,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [2680, 2802, 2026,  141, 4933,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 818, 2026, 2711,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [1992, 7040, 7643,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [1850, 6736, 2375,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:10], trainY[:10], testX[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 20), (10000, 4217), (2225, 20), (2225, 4217), (12226, 20))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "testX = np.array(testX)\n",
    "validX = trainX[:2225]\n",
    "trainX = trainX[2225:]\n",
    "trainY = to_categorical(trainY)\n",
    "validY = trainY[:2225]\n",
    "trainY = trainY[2225:]\n",
    "trainX.shape, trainY.shape, validX.shape, validY.shape, testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, SpatialDropout1D, BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam, Adagrad, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(200, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(200, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(200, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),    \n",
    "    Dense(out_size, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 32)             298592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 32)             128       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4217)              847617    \n",
      "=================================================================\n",
      "Total params: 1,280,537.0\n",
      "Trainable params: 1,279,273.0\n",
      "Non-trainable params: 1,264.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2225 samples\n",
      "Epoch 1/50\n",
      "  576/10000 [>.............................] - ETA: 14s - loss: 8.3924 - acc: 0.0017    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-cdff7d6b622b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, validation_data=(validX, validY), epochs=50, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single conv layer with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Dropout(0.2),\n",
    "    Conv1D(64, 5, padding='same', activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(out_size, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.fit(trainX, trainY, validation_data=(validX, validY), epochs=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.save_weights('conv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.load_weights('conv1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-size CNN\n",
    "* [Quid](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Merge\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_in = Input ((vocab_size, 50))\n",
    "convs = [ ] \n",
    "for fsz in range (3, 6): \n",
    "    x = Conv1D(64, fsz, padding='same', activation=\"relu\")(graph_in)\n",
    "    x = MaxPooling1D()(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x) \n",
    "    convs.append(x)\n",
    "out = Concatenate()(convs) \n",
    "graph = Model(graph_in, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2 = Sequential ([\n",
    "    Embedding(vocab_size, 50, input_length=seq_len),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense (100, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout (0.7),\n",
    "    Dense(out_size, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 50)            466550    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 50)            200       \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              multiple                  39360     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               192100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4217)              425917    \n",
      "=================================================================\n",
      "Total params: 1,124,527.0\n",
      "Trainable params: 1,123,843.0\n",
      "Non-trainable params: 684.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2225 samples\n",
      "Epoch 1/80\n",
      "10000/10000 [==============================] - 8s - loss: 8.2588 - acc: 0.0113 - val_loss: 7.9986 - val_acc: 0.0427\n",
      "Epoch 2/80\n",
      "10000/10000 [==============================] - 7s - loss: 7.7584 - acc: 0.0302 - val_loss: 7.9537 - val_acc: 0.0422\n",
      "Epoch 3/80\n",
      "10000/10000 [==============================] - 7s - loss: 7.3925 - acc: 0.0434 - val_loss: 8.0205 - val_acc: 0.0427\n",
      "Epoch 4/80\n",
      "10000/10000 [==============================] - 7s - loss: 7.1128 - acc: 0.0521 - val_loss: 7.5425 - val_acc: 0.0598\n",
      "Epoch 5/80\n",
      "10000/10000 [==============================] - 7s - loss: 6.8354 - acc: 0.0606 - val_loss: 7.3214 - val_acc: 0.0863\n",
      "Epoch 6/80\n",
      "10000/10000 [==============================] - 7s - loss: 6.5877 - acc: 0.0690 - val_loss: 7.1436 - val_acc: 0.1079\n",
      "Epoch 7/80\n",
      "10000/10000 [==============================] - 7s - loss: 6.3403 - acc: 0.0791 - val_loss: 6.9245 - val_acc: 0.1178\n",
      "Epoch 8/80\n",
      "10000/10000 [==============================] - 7s - loss: 6.0863 - acc: 0.0901 - val_loss: 6.7880 - val_acc: 0.1434\n",
      "Epoch 9/80\n",
      "10000/10000 [==============================] - 7s - loss: 5.8511 - acc: 0.1042 - val_loss: 6.6797 - val_acc: 0.1618\n",
      "Epoch 10/80\n",
      "10000/10000 [==============================] - 7s - loss: 5.6329 - acc: 0.1123 - val_loss: 6.5350 - val_acc: 0.1807\n",
      "Epoch 11/80\n",
      "10000/10000 [==============================] - 7s - loss: 5.4051 - acc: 0.1260 - val_loss: 6.4896 - val_acc: 0.1901\n",
      "Epoch 12/80\n",
      "10000/10000 [==============================] - 7s - loss: 5.2044 - acc: 0.1384 - val_loss: 6.3217 - val_acc: 0.2144\n",
      "Epoch 13/80\n",
      "10000/10000 [==============================] - 7s - loss: 5.0311 - acc: 0.1571 - val_loss: 6.2856 - val_acc: 0.2252\n",
      "Epoch 14/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.9301 - acc: 0.1585 - val_loss: 6.1945 - val_acc: 0.2315\n",
      "Epoch 15/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.7864 - acc: 0.1682 - val_loss: 6.2519 - val_acc: 0.2494\n",
      "Epoch 16/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.6013 - acc: 0.1831 - val_loss: 6.1584 - val_acc: 0.2584\n",
      "Epoch 17/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.4762 - acc: 0.1933 - val_loss: 6.1105 - val_acc: 0.2607\n",
      "Epoch 18/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.3559 - acc: 0.1999 - val_loss: 6.1493 - val_acc: 0.2733\n",
      "Epoch 19/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.1983 - acc: 0.2197 - val_loss: 6.1011 - val_acc: 0.2760\n",
      "Epoch 20/80\n",
      "10000/10000 [==============================] - 7s - loss: 4.0969 - acc: 0.2309 - val_loss: 6.0996 - val_acc: 0.2769\n",
      "Epoch 21/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.9910 - acc: 0.2381 - val_loss: 6.0702 - val_acc: 0.2863\n",
      "Epoch 22/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.9048 - acc: 0.2469 - val_loss: 6.0036 - val_acc: 0.3002\n",
      "Epoch 23/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.8342 - acc: 0.2505 - val_loss: 6.0619 - val_acc: 0.3056\n",
      "Epoch 24/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.7846 - acc: 0.2594 - val_loss: 6.1026 - val_acc: 0.2948\n",
      "Epoch 25/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.6578 - acc: 0.2650 - val_loss: 6.0864 - val_acc: 0.3088\n",
      "Epoch 26/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.5890 - acc: 0.2788 - val_loss: 6.0955 - val_acc: 0.3052\n",
      "Epoch 27/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.5310 - acc: 0.2790 - val_loss: 6.1337 - val_acc: 0.3133\n",
      "Epoch 28/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.4540 - acc: 0.2859 - val_loss: 6.1154 - val_acc: 0.3142\n",
      "Epoch 29/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.4163 - acc: 0.2969 - val_loss: 6.0532 - val_acc: 0.3213\n",
      "Epoch 30/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.3815 - acc: 0.3029 - val_loss: 6.1108 - val_acc: 0.3312\n",
      "Epoch 31/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.2824 - acc: 0.3143 - val_loss: 6.1374 - val_acc: 0.3353\n",
      "Epoch 32/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.2600 - acc: 0.3202 - val_loss: 6.0990 - val_acc: 0.3362\n",
      "Epoch 33/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.1816 - acc: 0.3200 - val_loss: 6.1999 - val_acc: 0.3375\n",
      "Epoch 34/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.1799 - acc: 0.3216 - val_loss: 6.3475 - val_acc: 0.3276\n",
      "Epoch 35/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.1013 - acc: 0.3310 - val_loss: 6.1182 - val_acc: 0.3506\n",
      "Epoch 36/80\n",
      "10000/10000 [==============================] - 7s - loss: 3.0658 - acc: 0.3395 - val_loss: 6.1234 - val_acc: 0.3483\n",
      "Epoch 37/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.9978 - acc: 0.3399 - val_loss: 6.1072 - val_acc: 0.3483\n",
      "Epoch 38/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.9672 - acc: 0.3474 - val_loss: 6.2037 - val_acc: 0.3515\n",
      "Epoch 39/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.9445 - acc: 0.3480 - val_loss: 6.1702 - val_acc: 0.3501\n",
      "Epoch 40/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.9040 - acc: 0.3559 - val_loss: 6.1882 - val_acc: 0.3560\n",
      "Epoch 41/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.8961 - acc: 0.3583 - val_loss: 6.2235 - val_acc: 0.3564\n",
      "Epoch 42/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.8336 - acc: 0.3686 - val_loss: 6.1610 - val_acc: 0.3587\n",
      "Epoch 43/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.8358 - acc: 0.3722 - val_loss: 6.1664 - val_acc: 0.3622\n",
      "Epoch 44/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.7658 - acc: 0.3733 - val_loss: 6.1825 - val_acc: 0.3600\n",
      "Epoch 45/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.7618 - acc: 0.3724 - val_loss: 6.2368 - val_acc: 0.3618\n",
      "Epoch 46/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.7284 - acc: 0.3866 - val_loss: 6.1595 - val_acc: 0.3627\n",
      "Epoch 47/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.7400 - acc: 0.3802 - val_loss: 6.2250 - val_acc: 0.3712\n",
      "Epoch 48/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.6758 - acc: 0.3950 - val_loss: 6.2880 - val_acc: 0.3663\n",
      "Epoch 49/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.6634 - acc: 0.3923 - val_loss: 6.2213 - val_acc: 0.3730\n",
      "Epoch 50/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.6488 - acc: 0.3973 - val_loss: 6.2676 - val_acc: 0.3735\n",
      "Epoch 51/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.6428 - acc: 0.4030 - val_loss: 6.2509 - val_acc: 0.3708\n",
      "Epoch 52/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.5689 - acc: 0.4069 - val_loss: 6.2625 - val_acc: 0.3658\n",
      "Epoch 53/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.5643 - acc: 0.4122 - val_loss: 6.3278 - val_acc: 0.3708\n",
      "Epoch 54/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.5629 - acc: 0.4121 - val_loss: 6.2830 - val_acc: 0.3721\n",
      "Epoch 55/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4952 - acc: 0.4177 - val_loss: 6.2886 - val_acc: 0.3685\n",
      "Epoch 56/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4892 - acc: 0.4187 - val_loss: 6.3257 - val_acc: 0.3726\n",
      "Epoch 57/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.5189 - acc: 0.4185 - val_loss: 6.2788 - val_acc: 0.3793\n",
      "Epoch 58/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4562 - acc: 0.4274 - val_loss: 6.2797 - val_acc: 0.3762\n",
      "Epoch 59/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4569 - acc: 0.4278 - val_loss: 6.3431 - val_acc: 0.3771\n",
      "Epoch 60/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4313 - acc: 0.4339 - val_loss: 6.3082 - val_acc: 0.3766\n",
      "Epoch 61/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4126 - acc: 0.4379 - val_loss: 6.3050 - val_acc: 0.3793\n",
      "Epoch 62/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.4062 - acc: 0.4351 - val_loss: 6.3274 - val_acc: 0.3834\n",
      "Epoch 63/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.3624 - acc: 0.4395 - val_loss: 6.3587 - val_acc: 0.3807\n",
      "Epoch 64/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.3852 - acc: 0.4376 - val_loss: 6.3741 - val_acc: 0.3780\n",
      "Epoch 65/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.3407 - acc: 0.4472 - val_loss: 6.3876 - val_acc: 0.3829\n",
      "Epoch 66/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.3202 - acc: 0.4505 - val_loss: 6.3476 - val_acc: 0.3852\n",
      "Epoch 67/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.3062 - acc: 0.4547 - val_loss: 6.3692 - val_acc: 0.3838\n",
      "Epoch 68/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2871 - acc: 0.4625 - val_loss: 6.3585 - val_acc: 0.3834\n",
      "Epoch 69/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2762 - acc: 0.4564 - val_loss: 6.3783 - val_acc: 0.3834\n",
      "Epoch 70/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2840 - acc: 0.4576 - val_loss: 6.3693 - val_acc: 0.3816\n",
      "Epoch 71/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2936 - acc: 0.4531 - val_loss: 6.3837 - val_acc: 0.3816\n",
      "Epoch 72/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2715 - acc: 0.4565 - val_loss: 6.4117 - val_acc: 0.3847\n",
      "Epoch 73/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2377 - acc: 0.4628 - val_loss: 6.3987 - val_acc: 0.3870\n",
      "Epoch 74/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2715 - acc: 0.4581 - val_loss: 6.3737 - val_acc: 0.3825\n",
      "Epoch 75/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.1989 - acc: 0.4688 - val_loss: 6.4495 - val_acc: 0.3838\n",
      "Epoch 76/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2087 - acc: 0.4721 - val_loss: 6.4456 - val_acc: 0.3861\n",
      "Epoch 77/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2100 - acc: 0.4743 - val_loss: 6.4247 - val_acc: 0.3901\n",
      "Epoch 78/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.2006 - acc: 0.4710 - val_loss: 6.4125 - val_acc: 0.3847\n",
      "Epoch 79/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.1851 - acc: 0.4767 - val_loss: 6.4610 - val_acc: 0.3879\n",
      "Epoch 80/80\n",
      "10000/10000 [==============================] - 7s - loss: 2.1744 - acc: 0.4736 - val_loss: 6.4449 - val_acc: 0.3856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b6f806358>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.fit(trainX, trainY, validation_data=(validX, validY), epochs=80, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2.save_weights('conv2_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2.load_weights('conv2_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2.fit(trainX, trainY, validation_data=(validX, validY), epochs=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = conv2.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12226, 4217)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('声門癌', 2987)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 = np.argmax(preds[0])\n",
    "int_to_after[i1], i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame(columns=[\"before\", \"after\"])\n",
    "for i in range(0, test_num):\n",
    "    for id in np.argsort(preds[i])[::-1][:3]:\n",
    "        series = pd.DataFrame([[test[0][i], int_to_after[id]]], columns=out.columns)\n",
    "        out = out.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = \"submission_conv2_20.tsv\"\n",
    "out.to_csv(subm_name, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_conv2_20.tsv' target='_blank'>submission_conv2_20.tsv</a><br>"
      ],
      "text/plain": [
       "/home/carnd/deepanalytics/bayer/submission_conv2_20.tsv"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_label = np.concatenate([trainY, preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([trainX, testX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22226, 8), (22226, 4217))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_feat.shape, comb_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22226 samples, validate on 2225 samples\n",
      "Epoch 1/50\n",
      "22226/22226 [==============================] - 14s - loss: 7.6470 - acc: 0.0416 - val_loss: 8.3595 - val_acc: 0.0103\n",
      "Epoch 2/50\n",
      "22226/22226 [==============================] - 13s - loss: 6.5301 - acc: 0.1045 - val_loss: 7.1490 - val_acc: 0.1187\n",
      "Epoch 3/50\n",
      "22226/22226 [==============================] - 13s - loss: 5.6817 - acc: 0.1669 - val_loss: 6.7113 - val_acc: 0.1789\n",
      "Epoch 4/50\n",
      "22226/22226 [==============================] - 13s - loss: 5.0921 - acc: 0.2201 - val_loss: 6.4245 - val_acc: 0.2216\n",
      "Epoch 5/50\n",
      "22226/22226 [==============================] - 13s - loss: 4.6661 - acc: 0.2755 - val_loss: 6.3359 - val_acc: 0.2620\n",
      "Epoch 6/50\n",
      "22226/22226 [==============================] - 13s - loss: 4.3675 - acc: 0.3175 - val_loss: 6.2411 - val_acc: 0.2894\n",
      "Epoch 7/50\n",
      "22226/22226 [==============================] - 13s - loss: 4.1139 - acc: 0.3521 - val_loss: 6.1962 - val_acc: 0.2998\n",
      "Epoch 8/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.9144 - acc: 0.3825 - val_loss: 6.2258 - val_acc: 0.3151\n",
      "Epoch 9/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.7605 - acc: 0.4055 - val_loss: 6.0638 - val_acc: 0.3218\n",
      "Epoch 10/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.6256 - acc: 0.4288 - val_loss: 6.1593 - val_acc: 0.3276\n",
      "Epoch 11/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.5040 - acc: 0.4487 - val_loss: 6.0687 - val_acc: 0.3348\n",
      "Epoch 12/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.4125 - acc: 0.4648 - val_loss: 6.0873 - val_acc: 0.3582\n",
      "Epoch 13/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.3235 - acc: 0.4813 - val_loss: 6.1144 - val_acc: 0.3564\n",
      "Epoch 14/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.2521 - acc: 0.4982 - val_loss: 6.1468 - val_acc: 0.3582\n",
      "Epoch 15/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.1789 - acc: 0.5082 - val_loss: 6.1282 - val_acc: 0.3663\n",
      "Epoch 16/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.1360 - acc: 0.5159 - val_loss: 6.1597 - val_acc: 0.3654\n",
      "Epoch 17/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.0680 - acc: 0.5305 - val_loss: 6.1018 - val_acc: 0.3690\n",
      "Epoch 18/50\n",
      "22226/22226 [==============================] - 13s - loss: 3.0326 - acc: 0.5383 - val_loss: 6.1906 - val_acc: 0.3748\n",
      "Epoch 19/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.9763 - acc: 0.5480 - val_loss: 6.2516 - val_acc: 0.3681\n",
      "Epoch 20/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.9518 - acc: 0.5500 - val_loss: 6.2360 - val_acc: 0.3663\n",
      "Epoch 21/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.9089 - acc: 0.5595 - val_loss: 6.3036 - val_acc: 0.3730\n",
      "Epoch 22/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.8778 - acc: 0.5689 - val_loss: 6.3132 - val_acc: 0.3708\n",
      "Epoch 23/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.8325 - acc: 0.5804 - val_loss: 6.3184 - val_acc: 0.3807\n",
      "Epoch 24/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.8078 - acc: 0.5813 - val_loss: 6.2911 - val_acc: 0.3762\n",
      "Epoch 25/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.7872 - acc: 0.5894 - val_loss: 6.3368 - val_acc: 0.3748\n",
      "Epoch 26/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.7561 - acc: 0.5925 - val_loss: 6.3218 - val_acc: 0.3775\n",
      "Epoch 27/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.7387 - acc: 0.5950 - val_loss: 6.3560 - val_acc: 0.3829\n",
      "Epoch 28/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.7247 - acc: 0.6009 - val_loss: 6.3477 - val_acc: 0.3856\n",
      "Epoch 29/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.7025 - acc: 0.6063 - val_loss: 6.4259 - val_acc: 0.3775\n",
      "Epoch 30/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.6660 - acc: 0.6142 - val_loss: 6.3425 - val_acc: 0.3834\n",
      "Epoch 31/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.6509 - acc: 0.6168 - val_loss: 6.3870 - val_acc: 0.3798\n",
      "Epoch 32/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.6351 - acc: 0.6230 - val_loss: 6.3664 - val_acc: 0.3838\n",
      "Epoch 33/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.6186 - acc: 0.6246 - val_loss: 6.3936 - val_acc: 0.3861\n",
      "Epoch 34/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.6071 - acc: 0.6324 - val_loss: 6.4057 - val_acc: 0.3820\n",
      "Epoch 35/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5908 - acc: 0.6306 - val_loss: 6.4033 - val_acc: 0.3820\n",
      "Epoch 36/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5797 - acc: 0.6325 - val_loss: 6.3706 - val_acc: 0.3892\n",
      "Epoch 37/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5541 - acc: 0.6395 - val_loss: 6.3955 - val_acc: 0.3847\n",
      "Epoch 38/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5586 - acc: 0.6389 - val_loss: 6.4065 - val_acc: 0.3834\n",
      "Epoch 39/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5280 - acc: 0.6462 - val_loss: 6.4415 - val_acc: 0.3843\n",
      "Epoch 40/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5270 - acc: 0.6442 - val_loss: 6.3853 - val_acc: 0.3816\n",
      "Epoch 41/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.5026 - acc: 0.6474 - val_loss: 6.3675 - val_acc: 0.3879\n",
      "Epoch 42/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4926 - acc: 0.6529 - val_loss: 6.3797 - val_acc: 0.3901\n",
      "Epoch 43/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4936 - acc: 0.6520 - val_loss: 6.3988 - val_acc: 0.3766\n",
      "Epoch 44/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4804 - acc: 0.6528 - val_loss: 6.4143 - val_acc: 0.3901\n",
      "Epoch 45/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4681 - acc: 0.6585 - val_loss: 6.4060 - val_acc: 0.3901\n",
      "Epoch 46/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4519 - acc: 0.6611 - val_loss: 6.3958 - val_acc: 0.3829\n",
      "Epoch 47/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4395 - acc: 0.6650 - val_loss: 6.3897 - val_acc: 0.3856\n",
      "Epoch 48/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4291 - acc: 0.6703 - val_loss: 6.4219 - val_acc: 0.3861\n",
      "Epoch 49/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4171 - acc: 0.6673 - val_loss: 6.4323 - val_acc: 0.3879\n",
      "Epoch 50/50\n",
      "22226/22226 [==============================] - 13s - loss: 2.4194 - acc: 0.6668 - val_loss: 6.4037 - val_acc: 0.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b085959e8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(comb_feat, comb_label, validation_data=(validX, validY), epochs=50, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
